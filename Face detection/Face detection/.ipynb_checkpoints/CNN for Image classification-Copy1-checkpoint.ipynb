{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf3e978",
   "metadata": {},
   "source": [
    "1) Here we are going to import the necessary libraries which are required for performing CNN tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ad3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c30c4",
   "metadata": {},
   "source": [
    "2) Here we required the following code to form the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83533b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (180,1)) ,\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n",
    "    tf.keras.layers.Dropout(0.1,seed = 2019),\n",
    "    tf.keras.layers.Dense(400,activation =\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3,seed = 2019),\n",
    "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.4,seed = 2019),\n",
    "    tf.keras.layers.Dense(200,activation =\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2,seed = 2019),\n",
    "    tf.keras.layers.Dense(5,activation = \"softmax\")   #Adding the Output Layer\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7db859",
   "metadata": {},
   "source": [
    "A convoluted image can be too large and so it is reduced without losing features or patterns, so pooling is done.\n",
    "\n",
    "Here Creating a Neural network is to initialize the network using the Sequential model from Keras.\n",
    "Flatten()- Flattening transforms a two-dimensional matrix of features into a vector of features.\n",
    "\n",
    "3) Now letâ€™s see a summary of the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf47d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 178, 178, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 89, 89, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 87, 87, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 43, 43, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 41, 41, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 20, 20, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 9, 9, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 10368)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 550)               5702950   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 550)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 400)               220400    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 300)               120300    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 5)                 1005      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6202295 (23.66 MB)\n",
      "Trainable params: 6202295 (23.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da6e77",
   "metadata": {},
   "source": [
    "4) So now we are required to specify optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2296c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "adam=Adam(lr=0.001)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5b64b6",
   "metadata": {},
   "source": [
    "Optimizer is used to reduce the cost calculated by cross-entropy\n",
    "\n",
    "The loss function is used to calculate the error\n",
    "\n",
    "The metrics term is used to represent the efficiency of the model\n",
    "\n",
    "5)In this step, we will see how to set the data directory and generate image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=30         #Setting batch size\n",
    "train_dir = \"D:/Data Science/Image Datasets/FastFood/train/\"   #Setting training directory\n",
    "validation_dir = \"D:/Data Science/Image Datasets/FastFood/test/\"   #Setting testing directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "#Flow_from_directory function lets the classifier directly identify the labels from the name of the directories the image lies in\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,batch_size=bs,class_mode='categorical',target_size=(180,180))\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode  = 'categorical',\n",
    "                                                         target_size=(180,180))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
