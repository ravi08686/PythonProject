{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8662b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69e288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('C:\\\\Users\\\\Administrator\\\\Documents\\\\GitHub\\\\opencv\\\\data\\\\haarcascades\\\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9414ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces= face_classifier.detectMultiScale(gray, 1.3,5)\n",
    "    if (len(faces)>0):\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3906fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.imread(\"C:\\\\Users\\\\Administrator\\\\Desktop\\\\Mine\\\\WhatsApp Images\\\\IMG-20211117-WA0006.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe4c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_faces(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces= face_classifier.detectMultiScale(gray, 1.3,5)\n",
    "    if (len(faces)>0): \n",
    "        for (x,y,w,h) in faces:\n",
    "            crop_img = img[y:y+h, x:x+w]\n",
    "            cv2.imshow(\"cropped\", crop_img)\n",
    "            cv2.waitKey(0)\n",
    "show_faces(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7bb1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    #ret, frame = cap.read()\n",
    "    #frame = detect_faces(frame)\n",
    "    frame = detect_faces(cap)\n",
    "    cv2.imshow('Video face detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "#cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2508bae5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'release'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelease\u001b[49m()\n\u001b[0;32m      9\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'release'"
     ]
    }
   ],
   "source": [
    "while False:\n",
    "    ret, frame = cap.read()\n",
    "    frame = detect_qfaces(frame)\n",
    "    cv2.imshow('Video face detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a61d9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('C:\\\\Users\\\\Administrator\\\\Documents\\\\GitHub\\\\opencv\\\\data\\\\haarcascades\\\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv2.imread(\"C:\\\\Users\\\\Administrator\\\\Desktop\\\\Mine\\\\WhatsApp Images\\\\IMG-20211117-WA0006.jpg\")\n",
    "width = 64\n",
    "height = 64\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces= face_classifier.detectMultiScale(gray, 1.3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70e80aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Define a list of image file paths\n",
    "image_paths = [\"C:\\\\Users\\\\Administrator\\\\Desktop\\\\Mine\\\\Untitled.jpg\", \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\Mine\\\\Untitled2.jpg\"]\n",
    "\n",
    "# Initialize variables\n",
    "current_image_index = 0\n",
    "\n",
    "# Function to show the next image\n",
    "def show_next_image(img):\n",
    "    global current_image_index\n",
    "    if current_image_index < len(faces):\n",
    "        face = faces[current_image_index]\n",
    "        load_and_display_image(face,img)\n",
    "        current_image_index += 1\n",
    "    else:\n",
    "        messagebox.showinfo(\"Finished\",\"All images are done!\")\n",
    "        root.destroy()\n",
    "\n",
    "# Function to load and display an image\n",
    "def load_and_display_image(face,img):\n",
    "    x,y,w,h = face\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "    dim = (64, 64)\n",
    "\n",
    "    # resize image\n",
    "    resized = cv2.resize(crop_img, dim, interpolation = cv2.INTER_AREA) \n",
    "    #image1 = Image.open(\"C:\\\\Users\\\\Administrator\\\\Desktop\\\\Mine\\\\Untitled.jpg\")\n",
    "    image1 = Image.fromarray(resized)\n",
    "    \n",
    "    #img = Image.open(image_path)\n",
    "    image2 = image1.resize((300, 300))  # Resize the image to fit the window\n",
    "    \n",
    "    photo = ImageTk.PhotoImage(image2)\n",
    "    image_label.config(image=photo)\n",
    "    image_label.image = photo  # Keep a reference to prevent garbage collection\n",
    "\n",
    "# Function to handle the \"Yes\" button\n",
    "def answer_yes():\n",
    "    show_next_image(img)\n",
    "\n",
    "# Function to handle the \"No\" button\n",
    "def answer_no():\n",
    "    show_next_image(img)\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Viewer\")\n",
    "\n",
    "# Create a label to display the images\n",
    "image_label = tk.Label(root)\n",
    "image_label.pack()\n",
    "\n",
    "# Create \"Yes\" and \"No\" buttons\n",
    "yes_button = tk.Button(root, text=\"Yes\", command=answer_yes)\n",
    "no_button = tk.Button(root, text=\"No\", command=answer_no)\n",
    "yes_button.pack(side=tk.LEFT)\n",
    "no_button.pack(side=tk.RIGHT)\n",
    "\n",
    "# Show the first image\n",
    "show_next_image(img)\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e21c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
