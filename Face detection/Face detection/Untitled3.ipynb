{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e017bf2b",
   "metadata": {},
   "source": [
    "## Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b990f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image as Im\n",
    "from PIL import ImageTk, ImageOps\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53820350",
   "metadata": {},
   "source": [
    "## All defined functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "597eb1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the folder\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            img = cv2.imread(os.path.join(folder_path, filename))\n",
    "            if img is not None:\n",
    "                images.append((filename, img))\n",
    "    return images\n",
    "\n",
    "# Step 2: Process images and collect face data\n",
    "def detect_faces(images):\n",
    "    face_data = []\n",
    "    #face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    face_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\ravik\\\\Documents\\\\GitHub\\\\opencv\\\\data\\\\haarcascades\\\\haarcascade_frontalface_default.xml')\n",
    "    tempnum = 0\n",
    "    for filename, img in images:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = gray[y:y+h, x:x+w]    \n",
    "            resized_face = cv2.resize(face, (180, 180))  # Define new_width and new_height   \n",
    "            tempnum = tempnum+1\n",
    "            faceId = \"face\"+str(tempnum)\n",
    "            face_data.append((faceId, filename, resized_face))\n",
    "    return face_data\n",
    "\n",
    "current_image_index = 0\n",
    "filename = \"\"\n",
    "user_choices = {}\n",
    "def show_image(face_data):\n",
    "    global current_image_index, user_choices, filename\n",
    "    #filename, faces = face_data\n",
    "    # Initialize variables\n",
    "    current_image_index = 0\n",
    "\n",
    "    # Function to show the next image\n",
    "    def show_next_image(face_data):\n",
    "        global current_image_index\n",
    "        if current_image_index < len(face_data):\n",
    "            face = face_data[current_image_index][2]\n",
    "            load_and_display_image(face)\n",
    "            current_image_index += 1\n",
    "        else:\n",
    "            messagebox.showinfo(\"Finished\",\"All images are done!\")\n",
    "            root.destroy()\n",
    "\n",
    "    # Function to load and display an image\n",
    "    def load_and_display_image(face):\n",
    "        image1 = Im.fromarray(face)\n",
    "        image2 = image1.resize((300, 300))  # Resize the image to fit the window\n",
    "        photo = ImageTk.PhotoImage(image2)\n",
    "        image_label.config(image=photo)\n",
    "        image_label.image = photo  # Keep a reference to prevent garbage collection\n",
    "\n",
    "    # Function to handle the \"Yes\" button\n",
    "    def answer_yes():\n",
    "        faceId = face_data[current_image_index-1][0]\n",
    "        user_choices[faceId] = 1\n",
    "        show_next_image(face_data)\n",
    "\n",
    "    # Function to handle the \"No\" button\n",
    "    def answer_no():\n",
    "        faceId = face_data[current_image_index-1][0]\n",
    "        user_choices[faceId] = 0\n",
    "        show_next_image(face_data)\n",
    "\n",
    "    # Create the main window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Image Viewer\")\n",
    "\n",
    "    # Create a label to display the images\n",
    "    image_label = tk.Label(root)\n",
    "    image_label.pack()\n",
    "\n",
    "    # Create \"Yes\" and \"No\" buttons\n",
    "    yes_button = tk.Button(root, text=\"Yes\", command=answer_yes)\n",
    "    no_button = tk.Button(root, text=\"No\", command=answer_no)\n",
    "    yes_button.pack(side=tk.LEFT)\n",
    "    no_button.pack(side=tk.RIGHT)\n",
    "\n",
    "    # Show the first image\n",
    "    show_next_image(face_data)\n",
    "\n",
    "    # Start the Tkinter main loop\n",
    "    root.mainloop()\n",
    "\n",
    "# Step 4: Append user choices to the existing dataframe\n",
    "def append_user_choices(dataframe, user_choices):\n",
    "    for faceId in user_choices:\n",
    "        dataframe.loc[dataframe['FaceId'] == faceId, 'Consider'] = user_choices[faceId]\n",
    "    return dataframe\n",
    "\n",
    "# Step 5: Prepare a convolution model for face recognition\n",
    "def create_face_recognition_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(2, activation='sigmoid')  # Binary classification (consider or not)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def show_verified_result(faces):\n",
    "    model_output = model.predict(faces)\n",
    "    \n",
    "    # Assuming 'predictions' is your array of probabilities\n",
    "    predictions = model_output\n",
    "\n",
    "    # Apply a threshold of 0.5 to convert probabilities to binary predictions\n",
    "    binary_predictions = (predictions >= 0.5).astype(int)\n",
    "    \n",
    "    # showing the results with images\n",
    "    counter=0\n",
    "    for imageName in faces:\n",
    "        NewImage = Im.fromarray(imageName)\n",
    "        #index_val = X_test.index(imageName)\n",
    "        if binary_predictions[counter] == 1:\n",
    "            expanded_im = ImageOps.expand(NewImage, border=20, fill='red')\n",
    "            display(expanded_im)\n",
    "        else:\n",
    "            display(NewImage)\n",
    "        counter=counter+1\n",
    "    return binary_predictions\n",
    "\n",
    "\n",
    "def identify_images(folder_path):\n",
    "    images = load_images_from_folder(folder_path)\n",
    "\n",
    "    face_data = detect_faces(images)\n",
    "\n",
    "    df_final = pd.DataFrame(data={\n",
    "        'FaceId': [faceId for faceId, _, _ in face_data],\n",
    "        'Filename': [filename for _, filename, _ in face_data],\n",
    "        'Face': [face for _, _, face in face_data],\n",
    "        'Consider': [0] * len(face_data)\n",
    "    })\n",
    "\n",
    "    # Convert the 'Face' column into NumPy arrays\n",
    "    X = np.array(df_final['Face'].tolist())\n",
    "\n",
    "    user_choices = show_verified_result(X)\n",
    "    df_final['Consider'] = user_choices\n",
    "    return df_final\n",
    "\n",
    "def move_images(source,destination):\n",
    "\n",
    "    # gather all files\n",
    "    allfiles = os.listdir(source)\n",
    "\n",
    "    # iterate on all files to move them to destination folder\n",
    "    for f in allfiles:\n",
    "        #consider_value = df_final.loc[df_final['Filename'] == f, 'Consider'].iloc[0]\n",
    "        #print(consider_value)\n",
    "        if (df_final.loc[df_final['Filename'] == f, 'Consider'] == 1).any():\n",
    "            print(\"consider as 1\")\n",
    "            src_path = os.path.join(source, f)\n",
    "            dst_path = os.path.join(destination, f)\n",
    "            os.rename(src_path, dst_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e046c94c",
   "metadata": {},
   "source": [
    "## Read the files and process them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13c2f4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    FaceId                 Filename  \\\n",
      "0    face1      20161006_222700.jpg   \n",
      "1    face2      20161007_203010.jpg   \n",
      "2    face3      20161007_203010.jpg   \n",
      "3    face4      20161007_203010.jpg   \n",
      "4    face5      20161007_203010.jpg   \n",
      "..     ...                      ...   \n",
      "74  face75  IMG_20220905_163224.jpg   \n",
      "75  face76  IMG_20220905_163224.jpg   \n",
      "76  face77  IMG_20220905_163224.jpg   \n",
      "77  face78  IMG_20220905_163224.jpg   \n",
      "78  face79  IMG_20220905_163224.jpg   \n",
      "\n",
      "                                                 Face  Consider  \n",
      "0   [[88, 87, 83, 81, 80, 85, 85, 77, 84, 80, 78, ...         0  \n",
      "1   [[254, 254, 250, 254, 252, 254, 243, 210, 157,...         0  \n",
      "2   [[174, 174, 174, 175, 175, 175, 175, 175, 175,...         0  \n",
      "3   [[111, 87, 80, 76, 65, 64, 54, 46, 37, 31, 33,...         0  \n",
      "4   [[185, 184, 186, 186, 186, 186, 185, 185, 184,...         0  \n",
      "..                                                ...       ...  \n",
      "74  [[217, 217, 205, 189, 174, 158, 143, 127, 111,...         0  \n",
      "75  [[76, 76, 79, 82, 85, 86, 86, 86, 82, 79, 78, ...         0  \n",
      "76  [[98, 98, 95, 92, 88, 86, 84, 81, 83, 87, 90, ...         0  \n",
      "77  [[63, 63, 64, 65, 63, 60, 62, 66, 69, 72, 74, ...         0  \n",
      "78  [[111, 129, 140, 127, 137, 141, 87, 90, 66, 72...         0  \n",
      "\n",
      "[79 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    source = \"C:\\\\Users\\\\ravik\\\\Desktop\\\\My images\\\\test\"\n",
    "    destination = 'C:\\\\Users\\\\ravik\\\\Desktop\\\\My images\\\\my pics'\n",
    "    \n",
    "    # Step 1: Read the folder\n",
    "    images = load_images_from_folder(source)\n",
    "    \n",
    "    # Step 2: Process images and collect face data\n",
    "    face_data = detect_faces(images)\n",
    "    # Create a DataFrame to store face data\n",
    "    df = pd.DataFrame(data={\n",
    "        'FaceId': [faceId for faceId, _, _ in face_data],\n",
    "        'Filename': [filename for _, filename, _ in face_data],\n",
    "        'Face': [face for _, _, face in face_data],\n",
    "        'Consider': [0] * len(face_data)\n",
    "    })\n",
    "    print(df)\n",
    "    \n",
    "    show_image(face_data)        \n",
    "\n",
    "    # Step 4: Append user choices to the existing dataframe\n",
    "    df = append_user_choices(df, user_choices)\n",
    "    df\n",
    "    \n",
    "    # Step 5: Prepare a convolution model for face recognition\n",
    "\n",
    "    X = np.array(df['Face'].tolist())\n",
    "    y = np.array(df['Consider'].tolist())\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    input_shape = X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99558756",
   "metadata": {},
   "source": [
    "## Train the data with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79053fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 6s 2s/step - loss: 29.3917 - accuracy: 0.4762 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 2s 955ms/step - loss: 28.6601 - accuracy: 0.9841 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 2s 1s/step - loss: 25.0261 - accuracy: 0.9841 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 2s 960ms/step - loss: 16.2402 - accuracy: 0.9841 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 2s 974ms/step - loss: 13.0406 - accuracy: 0.9841 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 2s 959ms/step - loss: 5.5196 - accuracy: 0.9841 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 2s 840ms/step - loss: 2.0572 - accuracy: 0.9841 - val_loss: 3.4066e-35 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 2s 876ms/step - loss: 2.2110e-06 - accuracy: 1.0000 - val_loss: 8.9640 - val_accuracy: 0.1875\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 2s 864ms/step - loss: 3.2287 - accuracy: 0.6984 - val_loss: 2.8396e-21 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 2s 862ms/step - loss: 0.5514 - accuracy: 0.9841 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 7.7555e-25 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Assume df is your DataFrame containing the data\n",
    "\n",
    "# Convert the 'Face' column into NumPy arrays\n",
    "X = df['Face'].tolist()\n",
    "\n",
    "# Filter out empty arrays and get the maximum length for non-empty arrays\n",
    "non_empty_X = [x for x in X if len(x) > 0]\n",
    "\n",
    "# Determine the maximum sequence length (number of values in each list)\n",
    "max_length = max(len(lst) for lst in non_empty_X)\n",
    "\n",
    "# Pad the sequences to make them uniform in length\n",
    "X_padded = pad_sequences(non_empty_X, maxlen=max_length, padding='post', dtype='float32')\n",
    "\n",
    "# Assuming the 'Consider' column represents the labels\n",
    "y = df['Consider'].values\n",
    "\n",
    "# Create and train the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(max_length, len(X_padded[0]), 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape the input data for CNN\n",
    "X_padded = X_padded.reshape(X_padded.shape[0], X_padded.shape[1], X_padded.shape[2], 1)\n",
    "\n",
    "# Step 6: Pass the dataframe to the convolution model\n",
    "# Train the model\n",
    "model.fit(X_padded, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dbc19a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 160ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'predictions' is your array of probabilities\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Apply a threshold of 0.5 to convert probabilities to binary predictions\n",
    "binary_predictions = (predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7853594",
   "metadata": {},
   "source": [
    "## Identify and move the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0868b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = identify_images(source)\n",
    "print(df_final)\n",
    "\n",
    "move_images(source,destination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
